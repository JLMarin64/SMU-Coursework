inTrain <- createDataPartition(y=spam$type, p=.75, list = FALSE)
#partitioning the data from spam that is in training and not in training
training <- spam[inTrain,]
testing <- spam[-inTrain,]
hist(training$capitalAve)
mean(training$capitalAve)
sd(training$capitalAve)
trainCapAveS < (trainCapAve - mean(trainCapAve))/sd(trainCapAve)
trainCapAve <- training$capitalAve
trainCapAveS <- (trainCapAve - mean(trainCapAve))/sd(trainCapAve)
mean(trainCapAveS)
mean(trainCapAveS)
sd(trainCapAveS)
testCapAveS <- (testCapAve - mean(trainCapAve))/sd(trainCapAve)
library(caret)
data("faithful")
data(faithful)
set.seed(333)
inTrain <- createDataPartition(y=faithful$waiting, p = .5, list = FALSE)
trainFaith <- faithful[inTrain,]
testFaith <- faithful[-inTrain,]
head(trainFaith)
plot(trainFaith$waiting, trainFaith$eruptions, pch = 19, col = "blue")
lm1 = lm(eruptions ~ waiting, data = trainFaith)
summary(lm1)
plot(trainFaith$waiting, trainFaith$eruptions, pch = 19, col = "blue")
lines(trainFaith$waiting, lm1$fitted, lwd = 3)
coef(lm1[1] + coef(lm1)[2]*80)
coef(lm1)[1] + coef(lm1)[2]*80)
coef(lm1)[1] + coef(lm1)[2]*80
newdata <- data.frame(waiting = 80)
predict(lm1, newdata)
sqrt(sum((lm1$fitted-trainFaith$eruptions)^2))
sqrt(sum((predict(lm1, newdata = testFaith)-testFaith$eruptions)^2))
pred1 <- predict(lm1, newdata= testFaith, interval= "prediction")
ord <- order(testFaith$waiting)
plot(testFaith, testFaith$eruptions, pch= 19, col = "blue")
matlines(testFaith$waiting[ord, pred1[ord,], type="l"],,col=c(1,2,2), lty = c(1,1,1), lwd=3)
matlines(testFaith$waiting[ord], pred1[ord,], type="l"],,col=c(1,2,2), lty = c(1,1,1), lwd=3)
matlines(testFaith$waiting[ord], pred1[ord,], type="l",,col=c(1,2,2), lty = c(1,1,1), lwd=3)
matlines(testFaith$waiting[ord], pred1[ord,], type="l",,col=c(1,2,2), lty = c(1,1,1), lwd=3)
modFit <- train(eruptions ~ waiting, data = trainFaith, method = "lm")
summary(modFit$finalModel)
library(ISLR)
library(ggplot2)
library(caret)
data(Wage)
Wage <- subset(Wage, select = -c(logwage))
summary(Wage)
inTrain <- createDataPartition(y=Wage$wage, p=.7, list = FALSE)
inTrain <- createDataPartition(y=Wage$wage, p=.7, list = FALSE)
training <- Wage[inTrain,]
test <- Wage[-inTrain,]
dim(training)
dim(test)
featurePlot(x=training[,c("age", "education", "jobclass")], y = training$wage, plot= "pairs")
qplot(age, wage, data = training)
qplot(age, wage, colour = jobclass, data = training)
qplot(age, wage, colour = education, data = training)
modFit <- train(wage ~ age + jobclass + education, method = "lm", data = training)
finMod <- modFit$finalModel
print(modFit)
modFit <- train(wage ~ age + jobclass + education, method = "lm", data = training)
finMod <- modFit$finalModel
print(modFit)
plot(finMod, 1, pch= 19, cex = .5, col="#000000010")
plot(finMod, 1, pch= 19, cex = .5, col="#00000010")
qplot(finMod$fitted, finMod$residuals, colour = race, data = training)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
library(rattle)
install.packages("rattle")
data(iris)
data(iris)
library(ggplot2)
names(iris)
table(iris$Species)
data(iris)
library(ggplot2)
names(iris)
table(iris$Species)
inTrain <- createDataPartition(y=iris$Species, p= .7, list = FALSE)
training <- iris[inTrain,]
testing <- iris[inTrain,]
dim(training); dim(testing)
qplot(Petal.Width, Sepal.Width, colour = Species, data = training)
library(caret)
modFit <- train(Species ~., method = "rpart", data = training)
print(modFit$finalModel)
plot(modFit$finalModel, uniform = TRUE, main = "Classification Tree")
text(modFit$finalModel, use.n=TRUE, all=TRUE, cex=.8)
text(modFit$finalModel, use.n=TRUE, all=TRUE, cex=.8)
plot(modFit$finalModel, uniform = TRUE, main = "Classification Tree")
text(modFit$finalModel, use.n=TRUE, all=TRUE, cex=.8)
text(modFit$finalModel, use.n=TRUE, all=TRUE, cex=.8)
plot(modFit$finalModel, uniform = TRUE, main = "Classification Tree")
plot(modFit$finalModel, uniform = TRUE, main = "Classification Tree")
text(modFi
plot(modFit$finalModel, uniform = TRUE, main = "Classification Tree")
modFit <- train(Species ~., method = "rpart", data = training)
print(modFit$finalModel)
plot(modFit$finalModel, uniform = TRUE, main = "Classification Tree")
text(modFit$finalModel, use.n = TRUE, all = TRUE, cex=.8)
install.packages("rattle")
library(rattle)
library(rattle)
library(rattle)
library(rattle)
fancyRpartPlot(modFit$finalModel)
fancyRpartPlot(modFit$finalModel)
library(rattle)
library(RGtk2)
fancyRpartPlot(modFit$finalModel)
fancyRpartPlot(modFit$finalModel)
installed.packages(rattle)
library(rattle)
install.packages(rattle)
install.packages("rattle")
library(rattle)
data(iris)
library(ggplot2)
names(iris)
table(iris$Species)
inTrain <- createDataPartition(y=iris$Species, p= .7, list = FALSE)
data(iris)
library(ggplot2)
library(caret)
names(iris)
table(iris$Species)
inTrain <- createDataPartition(y=iris$Species, p= .7, list = FALSE)
training <- iris[inTrain,]
testing <- iris[inTrain,]
dim(training); dim(testing)
qplot(Petal.Width, Sepal.Width, colour = Species, data = training)
modFit <- train(Species ~., method = "rpart", data = training)
print(modFit$finalModel)
plot(modFit$finalModel, uniform = TRUE, main = "Classification Tree")
text(modFit$finalModel, use.n = TRUE, all = TRUE, cex=.8)
library(rattle)
fancyRpartPlot(modFit$finalModel)
mem.limits(size = 8000)
mem.limits(size = 6000)
memory.limit(size = 8000)
memory.limit(size = 80000)
#Load Libraries
library(caret)
library(randomForest)
#Set Working Direcotry
setwd("C:/Users/Marin Family/Documents/R/Machine Learning Assignment")
#Set Seed
set.seed(1234)
#Load Downloaded Train and Test Files from Working Directory
training <- read.csv(file="pml-training.csv", na.strings=c("", "NA", "NULL"))
testing <- read.csv(file="pml-testing.csv", na.strings=c("", "NA", "NULL"))
#Remove NA columns and indentifier columns
training <- training[, colSums(is.na(training))==0]
dim(training)
#After review, the first 7 columns as they do not seem relevant to the outcome.
training <- training[,-c(1:7)]
testing <- testing[, -c(1:7)]
dim(training)
dim(testing)
#Create my test set
inTrain <- createDataPartition(y=training$classe, p=.7, list = FALSE)
trainset <- training[inTrain,]
#Create My Test Data
mytestset <- training[-inTrain,]
dim(trainset)
dim(mytestset)
#Load Coursera Test Data
testset <- read.csv("pml-testing.csv")
dim(testset)
modelfit <- train(classe ~., data = trainset, method = "rf", prox = TRUE)
modelfit$finalmodel
modelfit$finalmodel
modelfit <- train(classe ~., data = trainset, method = "rf")
modelfit$finalmodel
fitControl <- trainControl(method = "cv",
number = 10,
allowParallel = TRUE)
modelfit <- train(classe ~., data = trainset, method = "rf", trControl = fitControl)
library(caret)
library(randomForest)
library(parallel)
library(doParallel)
install.packages("doParallel")
library(doParallel)
cluster <- makeCluster(detectCores() - 1)
registerDoParallel(cluster)
#Load Libraries
library(caret)
library(randomForest)
library(parallel)
library(doParallel)
#Set Working Direcotry
setwd("C:/Users/Marin Family/Documents/R/Machine Learning Assignment")
#Set Seed
set.seed(1234)
#Load Downloaded Train and Test Files from Working Directory
training <- read.csv(file="pml-training.csv", na.strings=c("", "NA", "NULL"))
testing <- read.csv(file="pml-testing.csv", na.strings=c("", "NA", "NULL"))
#Remove NA columns and indentifier columns
training <- training[, colSums(is.na(training))==0]
dim(training)
#After review, the first 7 columns as they do not seem relevant to the outcome.
training <- training[,-c(1:7)]
testing <- testing[, -c(1:7)]
dim(training)
dim(testing)
#Create my test set
inTrain <- createDataPartition(y=training$classe, p=.7, list = FALSE)
trainset <- training[inTrain,]
#Create My Test Data
mytestset <- training[-inTrain,]
dim(trainset)
dim(mytestset)
#Load Coursera Test Data
testset <- read.csv("pml-testing.csv")
dim(testset)
cluster <- makeCluster(detectCores() - 1)
registerDoParallel(cluster)
fitControl <- trainControl(method = "cv",
number = 10,
allowParallel = TRUE)
modelfit <- train(classe ~., data = trainset, method = "rf", trControl = fitControl)
modelfit$finalmodel
cluster <- makeCluster(detectCores() - 1)
registerDoParallel(cluster)
fitControl <- trainControl(method = "cv",
number = 3,
allowParallel = TRUE)
modelfit <- train(classe ~., data = trainset, method = "rf", trControl = fitControl)
modelfit$finalmodel
corpus <- Corpus(VectorSource(c(blogs_sub, news_sub, twitter_sub)), readerControl=list(reader=readPlain,language="en"))
library(tm)
library(RWeka)
install.packages("ggplot")
corpus <- Corpus(VectorSource(c(blogs_sub, news_sub, twitter_sub)), readerControl=list(reader=readPlain,language="en"))
blogs <- readLines("./en_us.blogs.txt", encoding = "UTF-8", skipNul = TRUE)
library(tm)
library(RWeka)
library(ggplot2)
library(tm)
library(rJava)
library(RWeka)
library(dplyr)
library(ggplot2)
setwd("C:/Users/Marin Family/Desktop/New folder/Coursera-SwiftKey/final/en_US")
getwdd()
getwd()
setwd("C:/Users/Marin Family/Desktop/New folder/Coursera-SwiftKey/final/en_US")
unlink('Capstone Week 2 Assignment_cache', recursive = TRUE)
setwd("C:/Users/Marin Family/Desktop/New folder/Coursera-SwiftKey/final/en_US")
library(tm)
library(rJava)
library(RWeka)
library(dplyr)
library(ggplot2)
setwd("C:/Users/Marin Family/Desktop/New folder/Coursera-SwiftKey/final/en_US")
?bonferroni
??bonferroni
install.packages("decstools")
install.packages("desctools")
install.packages("DescTools")
knitr::opts_chunk$set(echo = TRUE)
setwd("C:/Users/Marin Family/Desktop/Doing Data Science/Unit 11/11")
Greg <- read.csv("Unit11TimeSeries_Gregorovitch.csv")
Greg <- read.csv("Unit11TimeSeries_Gregorovitch.csv")
Olli <- read.csv("Unit11TimeSeries_Ollivander.csv")
Greg <- read.csv("Unit11TimeSeries_Gregorovitch.csv")
Olli <- read.csv("Unit11TimeSeries_Ollivander.csv")
View(Greg)
View(Olli)
View(Greg)
View(Olli)
help("EuStockMarkets")
View(Greg)
help(read.csv)
Greg <- read.csv("Unit11TimeSeries_Gregorovitch.csv", header = FALSE)
Olli <- read.csv("Unit11TimeSeries_Ollivander.csv", header = FALSE
Olli <- read.csv("Unit11TimeSeries_Ollivander.csv", header = FALSE
Greg <- read.csv("Unit11TimeSeries_Gregorovitch.csv", header = FALSE)
Olli <- read.csv("Unit11TimeSeries_Ollivander.csv", header = FALSE)
?timeseries
??timeseries
View(Greg)
View(Olli)
help("EuStockMarkets")
dax <- EuStockMarkets
dax <- as.data.frame(EuStockMarkets)
View(dax)
EU <- as.data.frame(EuStockMarkets)
Dax <- as.data.frame(EU$DAX)
gift <- scan("http://robjhyndman.com/tsdldata/data/fancy.dat")
gift<- ts(gift, frequency=12, start=c(1987,1))
gift
gift <- scan("http://robjhyndman.com/tsdldata/data/fancy.dat")
Dax <- ts(Dax, frequency = 1, start = c(1991, 1))
Dax <- ts(Dax, frequency = 1, start = c(1991, 1998))
ts?
?ts
Dax <- ts(Dax, frequency = , start = 1991, end = 1998)
Dax <- ts(Dax, frequency = , start = 1991, end = 1998, frequency = 1 )
Dax <- ts(Dax, frequency = , start = 1991, frequency = 1)
Dax <- ts(Dax,  start = 1991, frequency = 1)
Dax <- ts(Dax,  start = 1991, frequency = 1)
plot(Dax)
plot(Dax)
abline(v=1997)
plot(Dax)
abline(v=1997, color = red)
plot(Dax, col = "blue")
abline(v=1997, col = "red")
DaxDecompse <- decompose(Dax, type = "mult")
DaxDecompse <- decompose(Dax, type = "add")
Dax <- ts(Dax,  start = 1991, frequency = 1)
summary(Dax)
Dax <- ts(Dax,  start = 1991, end = 1998, frequency = 1)
plot(Dax, col = "blue")
abline(v=1997, col = "red")
DaxDecompse <- decompose(Dax, type = "add")
DaxDecompse <- decompose(Dax, type = "mult")
Dax <- ts(Dax,  start = 1991, end = 1998, frequency = 4)
plot(Dax, col = "blue")
abline(v=1997, col = "red")
DaxDecompse <- decompose(Dax, type = "mult")
DaxDecompse <- decompose(Dax, type = "mult")
Dax <- ts(Dax,  start = 1991, end = 1998, frequency = 365)
plot(Dax, col = "blue")
abline(v=1997, col = "red")
Dax <- ts(Dax,  start = 1991, end = 1998, frequency = 4)
plot(Dax, col = "blue")
abline(v=1997, col = "red")
DaxDecompse <- decompose(Dax, type = "mult")
plot(DaxDecompse)
DaxDecompse <- decompose(Dax, type = "mult")
plot(DaxDecompse, col = "blue")
abline(v=1997, col = "red")
library(fpp2)
install.packages("fpp2")
library(fpp2)
maxitemp <- maxtemp
maxtemp <- as.data.frame(maxtemp)
View(maxtemp)
library(fpp2)
maxitemp <- maxtemp
maxtemp <- as.data.frame(maxitemp)
View(maxtemp)
maxtemp <- as.vector(maxitemp)
maxitemp
maxitemp <- window(maxitemp, start = 1990.5)
maxitemp <- window(maxitemp, start = 1990)
maxitemp <- maxtemp
maxitemp <- window(maxitemp, start = 1990)
maxitemp <- maxtemp
maxitemp <- window(maxitemp, start = 1989.5)
library(fpp2)
maxitemp <- maxtemp
maxitemp <- window(maxitemp, start = 1989.5)
library(fpp2)
maxitemp <- maxtemp
maxitemp <- window(maxitemp, start = 1989.5)
install.packages("dygraphs")
install.packages("forecast")
install.packages("forecast")
knitr::opts_chunk$set(echo = TRUE)
maxitemp <- maxtemp
maxitemp <- maxtemp
library(fpp2)
maxitemp <- maxtemp
maxitemp <- window(maxitemp, start = 1989.5)
?hw
maxtempf5 <- hw(maxitemp, initial = "optimal", h = 48)
maxtempf5 <- hw(maxitemp, initial = "optimal", h = 5)
ses(maxitemp, initial = "optimal", h = 5)
maxtempF5 <- ses(maxitemp, initial = "optimal", h = 5)
plot(maxtempF5)
maxtempF5 <- ses(maxitemp, initial = "optimal", h = 5)
maxtempF5 <- as.data.frame(ses(maxitemp, initial = "optimal", h = 5))
plot(maxtempF5)
maxtempF5 <-ses(maxitemp, initial = "optimal", h = 5)
plot(maxtempF5)
plot(maxtempF5)
lines(fitted(maxtempF5), col="blue")
summary(maxtempF5)
maxtempF5$residuals
maxtempF5$fitted
maxtempF5$method
maxtempF5$model
maxtempF5$model[1]
maxtempF5$model[2]
AIC <- maxtempF5$model[2]
AIC <- as.numeric(maxtempF5$model[2])
maxtempF5$model[3]
maxtempF5$model[4]
AICc <- as.numeric(maxtempF5$model[4])
holtmaxtempF <- holt(maxitemp, initial = "optimal" , h = 5)
plot(maxtempF5)
lines(fitted(maxtempF5), col="blue")
holtmaxtempF5$model[4]
holtmaxtempF$model[4]
holtAICc <- holtmaxtempF$model[4]
holtAICc <- as.numeric(holtmaxtempF$model[4])
print("hello")
if (AICc < holtAICc)
{
print("The SES AICc is better.")
}
else
if (AICc < holtAICc)
{
print("The SES AICc is better.")
}
else
if (AICc < holtAICc)
{
print("The SES AICc is better.")
} else {
print("The Holt AICc is better.")
}
install.packages("dygraphs")
library(dygraphs)
setwd("C:/Users/Marin Family/Desktop/Doing Data Science/Unit 11/11")
?read.csv
Greg <- read.csv("Unit11TimeSeries_Gregorovitch.csv", header = FALSE)
Ollie <- read.csv("Unit11TimeSeries_Ollivander.csv", header = FALSE)
head(Greg)
class$Greg
class(Greg$V1)
as.Date(Greg$V1)
class(Greg$V1)
View(Greg)
Greg$V1 <- as.Date.date(Greg$V1)
Greg$V1 <- as.Date.character(Greg$V1)
View(Greg)
Greg <- read.csv("Unit11TimeSeries_Gregorovitch.csv", header = FALSE)
Ollie <- read.csv("Unit11TimeSeries_Ollivander.csv", header = FALSE)
class(Greg$V1)
Greg$V1 <- as.Date.factor(Greg$V1)
View(Greg)
Greg <- read.csv("Unit11TimeSeries_Gregorovitch.csv", header = FALSE)
Ollie <- read.csv("Unit11TimeSeries_Ollivander.csv", header = FALSE)
Greg$V1 <- as.Date(Greg$V1, format = "%m/%d/%Y")
class(Greg$V1)
View(Greg)
Ollive$V1 <- as.date(Ollie$V1, format = "%m/%d/%Y")
Ollive$V1 <- as.Date(Ollie$V1, format = "%m/%d/%Y")
Ollie$V1 <- as.Date(Ollie$V1, format = "%m/%d/%Y")
View(Ollie)
library(sqldf)
Wand <- sqldf("Select * from Greg union Select * from Ollie")
Wand <- sqldf("Select 'Gregorovitch' as 'Maker', V1 as 'Date', V2 as 'Units'  from Greg union Select 'Ollivander' as 'Maker', V1 as 'Date', V2 as 'Units'  from Ollie order")
Wand <- sqldf("Select 'Gregorovitch' as 'Maker', V1 as 'Date', V2 as 'Units'  from Greg union Select 'Ollivander' as 'Maker', V1 as 'Date', V2 as 'Units'  from Ollie")
WandOrder <- sqldf("select *  from Wand order by Date desc")
View(WandOrder)
class(WandOrder$Date)
Greg$Maker <- Gregorovitch
Greg$Maker <- "Gregorovitch"
Ollie$Make <- "Ollivander"
?rbind
Wand <- rbind(Greg, Ollie)
library(dygraphs)
library(sqldf)
Greg <- read.csv("Unit11TimeSeries_Gregorovitch.csv", header = FALSE)
Ollie <- read.csv("Unit11TimeSeries_Ollivander.csv", header = FALSE)
class(Greg$V1)
Greg$V1 <- as.Date(Greg$V1, format = "%m/%d/%Y")
Ollie$V1 <- as.Date(Ollie$V1, format = "%m/%d/%Y")
Greg$Maker <- "Gregorovitch"
Ollie$Maker <- "Ollivander"
Wand <- rbind(Greg, Ollie)
Wand <- wand[order(date),]
Wand <- Wand[order(date),]
Wand <- Wand[order(V1),]
View(Wand)
Wand <- Wand[order(Wand$V1),]
colnames(Wand)[colanes(Wand)=="V1"] <- "Date"
colnames(Wand)[colnames(Wand)=="V1"] <- "Date"
colnames(Wand)[colnames(Wand)=="V2"] <- "Units"
?dygraph
dygraph(Wand, main="Wands Sold by Year", ylab="Units", xlab="Date", group = "Maker") %>%
dyRangeSelector(height=100) %>%
dyShading(from = "1995-1-1", to = "1956-1-1", color = "#FFE6E6") %>%
dyShading(from = "1999-1-1", to = "1960-1-1", color = "#CCEBD6")
Wandts <- ts(Wand, frequency = 12, start = c(1970,2017))
Wandts <- ts(Wand, frequency = 1, start = c(1970,2017))
Wandts <- ts(Wand,  start = c(1970,2017))
Wandts <- ts(Wand, frequency = 2, start = c(1970,2017))
?ts
Wandts <- ts(Wand$Units, frequency = 12, start = c(1970,2017))
Wandts <- ts(Wand$Units, frequency = 1, start = c(1970,2017))
install.packages("xts")
install.packages("xts")
knitr::opts_chunk$set(echo = TRUE)
library(xts)
install.packages("xts")
library(xts)
install.packages("xts")
library(xts)
library(xts)
install.packages("xts", repos="http://cloud.r-project.org")
library(xts)
install.packages("zoo")
library(xts)
install.packages("xts", repos="http://cloud.r-project.org")
library(xts)
remove.packages(xts)
