sqrt(sum((predict(lm1, newdata = testFaith)-testFaith$eruptions)^2))
pred1 <- predict(lm1, newdata= testFaith, interval= "prediction")
ord <- order(testFaith$waiting)
plot(testFaith, testFaith$eruptions, pch= 19, col = "blue")
matlines(testFaith$waiting[ord, pred1[ord,], type="l"],,col=c(1,2,2), lty = c(1,1,1), lwd=3)
matlines(testFaith$waiting[ord], pred1[ord,], type="l"],,col=c(1,2,2), lty = c(1,1,1), lwd=3)
matlines(testFaith$waiting[ord], pred1[ord,], type="l",,col=c(1,2,2), lty = c(1,1,1), lwd=3)
matlines(testFaith$waiting[ord], pred1[ord,], type="l",,col=c(1,2,2), lty = c(1,1,1), lwd=3)
modFit <- train(eruptions ~ waiting, data = trainFaith, method = "lm")
summary(modFit$finalModel)
library(ISLR)
library(ggplot2)
library(caret)
data(Wage)
Wage <- subset(Wage, select = -c(logwage))
summary(Wage)
inTrain <- createDataPartition(y=Wage$wage, p=.7, list = FALSE)
inTrain <- createDataPartition(y=Wage$wage, p=.7, list = FALSE)
training <- Wage[inTrain,]
test <- Wage[-inTrain,]
dim(training)
dim(test)
featurePlot(x=training[,c("age", "education", "jobclass")], y = training$wage, plot= "pairs")
qplot(age, wage, data = training)
qplot(age, wage, colour = jobclass, data = training)
qplot(age, wage, colour = education, data = training)
modFit <- train(wage ~ age + jobclass + education, method = "lm", data = training)
finMod <- modFit$finalModel
print(modFit)
modFit <- train(wage ~ age + jobclass + education, method = "lm", data = training)
finMod <- modFit$finalModel
print(modFit)
plot(finMod, 1, pch= 19, cex = .5, col="#000000010")
plot(finMod, 1, pch= 19, cex = .5, col="#00000010")
qplot(finMod$fitted, finMod$residuals, colour = race, data = training)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
library(rattle)
install.packages("rattle")
data(iris)
data(iris)
library(ggplot2)
names(iris)
table(iris$Species)
data(iris)
library(ggplot2)
names(iris)
table(iris$Species)
inTrain <- createDataPartition(y=iris$Species, p= .7, list = FALSE)
training <- iris[inTrain,]
testing <- iris[inTrain,]
dim(training); dim(testing)
qplot(Petal.Width, Sepal.Width, colour = Species, data = training)
library(caret)
modFit <- train(Species ~., method = "rpart", data = training)
print(modFit$finalModel)
plot(modFit$finalModel, uniform = TRUE, main = "Classification Tree")
text(modFit$finalModel, use.n=TRUE, all=TRUE, cex=.8)
text(modFit$finalModel, use.n=TRUE, all=TRUE, cex=.8)
plot(modFit$finalModel, uniform = TRUE, main = "Classification Tree")
text(modFit$finalModel, use.n=TRUE, all=TRUE, cex=.8)
text(modFit$finalModel, use.n=TRUE, all=TRUE, cex=.8)
plot(modFit$finalModel, uniform = TRUE, main = "Classification Tree")
plot(modFit$finalModel, uniform = TRUE, main = "Classification Tree")
text(modFi
plot(modFit$finalModel, uniform = TRUE, main = "Classification Tree")
modFit <- train(Species ~., method = "rpart", data = training)
print(modFit$finalModel)
plot(modFit$finalModel, uniform = TRUE, main = "Classification Tree")
text(modFit$finalModel, use.n = TRUE, all = TRUE, cex=.8)
install.packages("rattle")
library(rattle)
library(rattle)
library(rattle)
library(rattle)
fancyRpartPlot(modFit$finalModel)
fancyRpartPlot(modFit$finalModel)
library(rattle)
library(RGtk2)
fancyRpartPlot(modFit$finalModel)
fancyRpartPlot(modFit$finalModel)
installed.packages(rattle)
library(rattle)
install.packages(rattle)
install.packages("rattle")
library(rattle)
data(iris)
library(ggplot2)
names(iris)
table(iris$Species)
inTrain <- createDataPartition(y=iris$Species, p= .7, list = FALSE)
data(iris)
library(ggplot2)
library(caret)
names(iris)
table(iris$Species)
inTrain <- createDataPartition(y=iris$Species, p= .7, list = FALSE)
training <- iris[inTrain,]
testing <- iris[inTrain,]
dim(training); dim(testing)
qplot(Petal.Width, Sepal.Width, colour = Species, data = training)
modFit <- train(Species ~., method = "rpart", data = training)
print(modFit$finalModel)
plot(modFit$finalModel, uniform = TRUE, main = "Classification Tree")
text(modFit$finalModel, use.n = TRUE, all = TRUE, cex=.8)
library(rattle)
fancyRpartPlot(modFit$finalModel)
mem.limits(size = 8000)
mem.limits(size = 6000)
memory.limit(size = 8000)
memory.limit(size = 80000)
#Load Libraries
library(caret)
library(randomForest)
#Set Working Direcotry
setwd("C:/Users/Marin Family/Documents/R/Machine Learning Assignment")
#Set Seed
set.seed(1234)
#Load Downloaded Train and Test Files from Working Directory
training <- read.csv(file="pml-training.csv", na.strings=c("", "NA", "NULL"))
testing <- read.csv(file="pml-testing.csv", na.strings=c("", "NA", "NULL"))
#Remove NA columns and indentifier columns
training <- training[, colSums(is.na(training))==0]
dim(training)
#After review, the first 7 columns as they do not seem relevant to the outcome.
training <- training[,-c(1:7)]
testing <- testing[, -c(1:7)]
dim(training)
dim(testing)
#Create my test set
inTrain <- createDataPartition(y=training$classe, p=.7, list = FALSE)
trainset <- training[inTrain,]
#Create My Test Data
mytestset <- training[-inTrain,]
dim(trainset)
dim(mytestset)
#Load Coursera Test Data
testset <- read.csv("pml-testing.csv")
dim(testset)
modelfit <- train(classe ~., data = trainset, method = "rf", prox = TRUE)
modelfit$finalmodel
modelfit$finalmodel
modelfit <- train(classe ~., data = trainset, method = "rf")
modelfit$finalmodel
fitControl <- trainControl(method = "cv",
number = 10,
allowParallel = TRUE)
modelfit <- train(classe ~., data = trainset, method = "rf", trControl = fitControl)
library(caret)
library(randomForest)
library(parallel)
library(doParallel)
install.packages("doParallel")
library(doParallel)
cluster <- makeCluster(detectCores() - 1)
registerDoParallel(cluster)
#Load Libraries
library(caret)
library(randomForest)
library(parallel)
library(doParallel)
#Set Working Direcotry
setwd("C:/Users/Marin Family/Documents/R/Machine Learning Assignment")
#Set Seed
set.seed(1234)
#Load Downloaded Train and Test Files from Working Directory
training <- read.csv(file="pml-training.csv", na.strings=c("", "NA", "NULL"))
testing <- read.csv(file="pml-testing.csv", na.strings=c("", "NA", "NULL"))
#Remove NA columns and indentifier columns
training <- training[, colSums(is.na(training))==0]
dim(training)
#After review, the first 7 columns as they do not seem relevant to the outcome.
training <- training[,-c(1:7)]
testing <- testing[, -c(1:7)]
dim(training)
dim(testing)
#Create my test set
inTrain <- createDataPartition(y=training$classe, p=.7, list = FALSE)
trainset <- training[inTrain,]
#Create My Test Data
mytestset <- training[-inTrain,]
dim(trainset)
dim(mytestset)
#Load Coursera Test Data
testset <- read.csv("pml-testing.csv")
dim(testset)
cluster <- makeCluster(detectCores() - 1)
registerDoParallel(cluster)
fitControl <- trainControl(method = "cv",
number = 10,
allowParallel = TRUE)
modelfit <- train(classe ~., data = trainset, method = "rf", trControl = fitControl)
modelfit$finalmodel
cluster <- makeCluster(detectCores() - 1)
registerDoParallel(cluster)
fitControl <- trainControl(method = "cv",
number = 3,
allowParallel = TRUE)
modelfit <- train(classe ~., data = trainset, method = "rf", trControl = fitControl)
modelfit$finalmodel
corpus <- Corpus(VectorSource(c(blogs_sub, news_sub, twitter_sub)), readerControl=list(reader=readPlain,language="en"))
library(tm)
library(RWeka)
install.packages("ggplot")
corpus <- Corpus(VectorSource(c(blogs_sub, news_sub, twitter_sub)), readerControl=list(reader=readPlain,language="en"))
blogs <- readLines("./en_us.blogs.txt", encoding = "UTF-8", skipNul = TRUE)
library(tm)
library(RWeka)
library(ggplot2)
library(tm)
library(rJava)
library(RWeka)
library(dplyr)
library(ggplot2)
setwd("C:/Users/Marin Family/Desktop/New folder/Coursera-SwiftKey/final/en_US")
getwdd()
getwd()
setwd("C:/Users/Marin Family/Desktop/New folder/Coursera-SwiftKey/final/en_US")
unlink('Capstone Week 2 Assignment_cache', recursive = TRUE)
setwd("C:/Users/Marin Family/Desktop/New folder/Coursera-SwiftKey/final/en_US")
library(tm)
library(rJava)
library(RWeka)
library(dplyr)
library(ggplot2)
setwd("C:/Users/Marin Family/Desktop/New folder/Coursera-SwiftKey/final/en_US")
?bonferroni
??bonferroni
install.packages("decstools")
install.packages("desctools")
install.packages("DescTools")
gift <- scan("http://robjhyndman.com/tsdldata/data/fancy.dat")
gift<- ts(gift, frequency=12, start=c(1987,1))
gift
births <- scan("http://robjhyndman.com/tsdldata/data/nybirths.dat")
births <- ts(births, frequency = 12, start = c(1946, 1))  #frequency =12 because its a monthly dataset, 1=yearly, 4=quarterly
births
plot(births)  #additive or multiplicative?
plot(gift)    #additive or multiplicative?
giftComp <- decompose(gift, type="mult")
plot(giftComp)
birthsComp <- decompose(births, type="add")
plot(birthsComp)
#forecast for next 48 months
#start from 1952
#blue line: actual prediction, dark gray: 80% confidence interval, light gray: 95% confidence interval
birthsSubset<-window(births, start=1952)
birthsF5 <- hw(birthsSubset, initial="optimal", h=48)
plot(birthsF5)
lines(fitted(birthsF5), col="red")
birthsSubset<-window(births, start=1952)
birthsF5 <- hw(birthsSubset, initial="optimal", h=48)
plot(birthsF5)
birthsSubset<-window(births, start=1952)
birthsF5 <- hw(birthsSubset, initial="optimal", h=48)
birthsHW <- HoltWinters(births)
birthsHW
plot(birthsHW)
birthsSubset<-window(births, start=1952)
birthsF5 <- hw(birthsSubset, initial="optimal", h=48)
plot(birthsF5)
lines(fitted(birthsF5), col="red")
birthsSubset<-window(births, start=1952)
birthsF5 <- hw(birthsSubset, initial="optimal", h=48)
#Live Session 12 demo
install.packages("dygraphs")
library("dygraphs")
install.packages("forecast")
library("forecast")
setwd("C:/Users/Marin Family/Desktop/Statistical Foundations for Data Science/Unit 12")
library(xlsx)
read.xlsx("MammalProb22_2_2_2_2.xlsx",sheet = "Mammal Prob 22")
read.xlsx(file = "MammalProb22_2_2_2_2.xlsx",sheet = "Mammal Prob 22")
?read.xlsx
read.xlsx(file = "MammalProb22_2_2_2_2.xlsx",sheetName = "Mammal Prob 22")
Mammal <- read.xlsx(file = "MammalProb22_2_2_2_2.xlsx",sheetName = "Mammal Prob 22")
library(xlsx)
setwd("C:/Users/Marin Family/Desktop/Statistical Foundations for Data Science/Unit 12")
Mammal <- read.xlsx(file = "MammalProb22_2_2_2_2.xlsx",sheetName = "Mammal Prob 22")
View(Mammal)
setwd("C:/Users/Marin Family/Desktop/Statistical Foundations for Data Science/Unit 12")
Brain <- read.xlsx(file = "Brain_2_2_2",sheetName = "Brain")
Brain <- read.xlsx(file = "Brain_2_2_2.xlsx",sheetName = "Brain")
View(Mammal)
library(xlsx)
setwd("C:/Users/Marin Family/Desktop/Statistical Foundations for Data Science/Unit 12")
Brain <- read.xlsx(file = "Brain_2_2_2.xlsx",sheetName = "Brain")
View(Brain)
View(Brain)
class(Brain$Body)
options(scipen=999)
View(Brain)
lm(formula = Y~ X + Gestatition + Litter + Body, data = Brain )
lm(formula = Brain ~ Gestatition + Litter + Body, data = Brain )
lm(formula = Brain ~ Gestation + Litter + Body, data = Brain )
model <- lm(formula = Brain ~ Gestation + Litter + Body, data = Brain )
summary(model)
plot(Brain)
plot(Brain$Species)
plot(Brain)
library(olsrr)
ols_rsd_qqplot(model)
ols_rvsp_plot(model)
##histogram
ols_rsd_hist(model)
plot(model)
plot(model)
summary(model)
model <- lm(formula = Brain ~ Body + Litter + Getation, data = Brain )
model <- lm(formula = Brain ~ Body + Litter + Gestation, data = Brain )
sumary(model)
summary(model)
summary(model)
ols_rsd_qqplot(model)
ols_rvsp_plot(model)
##histogram
ols_rsd_hist(model)
ols_rsd_qqplot(model)
ols_rsd_hist(model)
ols_rsd_qqplot(model)
head(Brain)
BrainLog <- "select Species, log(Brain) as LogBrain, log(Body) as LogBody, log(Gestation) as LogGestation, log(Litter)
as LogLitter from Brain"
BrainLog <- sqldf("select Species, log(Brain) as LogBrain, log(Body) as LogBody, log(Gestation) as LogGestation, log(Litter)
as LogLitter from Brain")
library(sqldf)
BrainLog <- sqldf("select Species, log(Brain) as LogBrain, log(Body) as LogBody, log(Gestation) as LogGestation, log(Litter)
as LogLitter from Brain")
View(BrainLog)
model <- lm(formula = LogBrain ~ LogBody + LogLitter + LogGestation, data = BrainLog )
ols_rsd_qqplot(model)
ols_rvsp_plot(model)
ols_rsd_hist(model)
plot(Brain)
plot(BrainLog)
plot(Brain)
plot(BrainLog)
summary(model)
Brain$Body <- null
Brain$Body <- NULL
model <- lm(formula = Brain ~ Body + Litter + Gestation, data = BrainLog )
model <- lm(formula = Brain ~  Litter + Gestation, data = Brain )
summary(model)
ols_rsd_qqplot(model)
model <- lm(formula = LogBrain ~  LogLitter + LogGestation, data = BrainLog )
ols_rsd_qqplot(model)
ols_rvsp_plot(model)
ols_rsd_hist(model)
plot(Brain)
plot(BrainLog)
#qqplot
ols_rsd_qqplot(model)
ols_rvsp_plot(model)
ols_rsd_hist(model)
plot(model)
View(Brain)
model <- lm(formula = Brain ~ Species + Litter + Gestation, data = Brain )
summary(model)
model <- lm(formula = Brain ~  Litter + Gestation, data = Brain )
summary(model)
Brain$Body <- NULL
Brain$Species <- NULL
BrainLog <- sqldf("Select log(Brain) as LogBrain,  log(Gestation) as LogGestation, log(Litter)
as LogLitter from Brain")
plot(Brain)
plot(BrainLog)
model <- lm(formula = Brain ~  Litter + Gestation, data = Brain )
summary(model)
model <- lm(formula = LogBrain ~  LogLitter + LogGestation, data = BrainLog )
summary(model)
model$terms
model$residuals
model$coefficients
summary(model)
model$qr
model$effects
setwd("C:/Users/Marin Family/Desktop/Statistical Foundations for Data Science/Unit 12")
Brain <- read.xlsx(file = "Brain_2_2_2.xlsx",sheetName = "Brain")
library(xlsx)
library(olsrr)
library(sqldf)
setwd("C:/Users/Marin Family/Desktop/Statistical Foundations for Data Science/Unit 12")
Brain <- read.xlsx(file = "Brain_2_2_2.xlsx",sheetName = "Brain")
Brain$Species <- NULL
BrainLog <- sqldf("Select log(Brain) as LogBrain, log(Body) as LogBody, log(Gestation) as LogGestation, log(Litter)
as LogLitter from Brain")
model <- lm(formula = Brain ~  Body + Litter + Gestation, data = Brain )
model <- lm(formula = Brain ~  Body + Litter + Gestation, data = Brain )
summary(model)
model <- lm(formula = LogBrain ~ LogBody + LogLitter + LogGestation, data = BrainLog )
summary(model)
plot(Brain)
plot(BrainLog)
plot(Brain)
plot(BrainLog)
10^27.65
model <- lm(formula = LogBrain ~ LogBody + LogLitter + LogGestation, data = BrainLog )
summary(model)
10^-.31007
confit(model)
confint(model)
?confint
confint(model, level = .95)
10^-.54
10^-.080
10^.42
10^.138
10^.6975
?plot
birthsSubset<-window(births, start=1952)
#Live Session 12 demo
install.packages("dygraphs")
library("dygraphs")
install.packages("forecast")
#Live Session 12 demo
install.packages("dygraphs")
library("dygraphs")
install.packages("forecast")
library("forecast")
#read, convert and display births timeseries dataset
births <- scan("http://robjhyndman.com/tsdldata/data/nybirths.dat")
births <- ts(births, frequency = 12, start = c(1946, 1))  #frequency =12 because its a monthly dataset, 1=yearly, 4=quarterly
births
#read, convert and display gift shop dataset
gift <- scan("http://robjhyndman.com/tsdldata/data/fancy.dat")
gift<- ts(gift, frequency=12, start=c(1987,1))
gift
#plot births and gift timeseries - both have seasonal components
plot(births)  #additive or multiplicative?
plot(gift)    #additive or multiplicative?
abline(v=1992, col="red")
#decompose seasonal data
birthsComp <- decompose(births, type="add")
plot(birthsComp)
giftComp <- decompose(gift, type="mult")
plot(giftComp)
#HoltWinters filtering on births
birthsHW <- HoltWinters(births)
birthsHW
plot(birthsHW)
#forecast for next 48 months
#start from 1952
#blue line: actual prediction, dark gray: 80% confidence interval, light gray: 95% confidence interval
birthsSubset<-window(births, start=1952)
class(birthsSubset)
#plot births and gift timeseries - both have seasonal components
plot(births)  #additive or multiplicative?
plot(gift)    #additive or multiplicative?
abline(v=1992, col="red")
#decompose seasonal data
birthsComp <- decompose(births, type="add")
plot(birthsComp)
giftComp <- decompose(gift, type="mult")
plot(giftComp)
#HoltWinters filtering on births
birthsHW <- HoltWinters(births)
birthsHW
plot(birthsHW)
#forecast for next 48 months
#start from 1952
#blue line: actual prediction, dark gray: 80% confidence interval, light gray: 95% confidence interval
birthsSubset<-window(births, start=1952)
birthsF5 <- hw(birthsSubset, initial="optimal", h=48)
plot(birthsF5)
lines(fitted(birthsF5), col="red")
#Live Session 12 demo
install.packages("dygraphs")
library("dygraphs")
install.packages("forecast")
#Live Session 12 demo
#install.packages("dygraphs")
library("dygraphs")
#install.packages("forecast")
library("forecast")
#read, convert and display births timeseries dataset
births <- scan("http://robjhyndman.com/tsdldata/data/nybirths.dat")
births <- ts(births, frequency = 12, start = c(1946, 1))  #frequency =12 because its a monthly dataset, 1=yearly, 4=quarterly
births
#read, convert and display gift shop dataset
gift <- scan("http://robjhyndman.com/tsdldata/data/fancy.dat")
gift<- ts(gift, frequency=12, start=c(1987,1))
gift
#plot births and gift timeseries - both have seasonal components
plot(births)  #additive or multiplicative?
plot(gift)    #additive or multiplicative?
abline(v=1992, col="red")
#decompose seasonal data
birthsComp <- decompose(births, type="add")
plot(birthsComp)
giftComp <- decompose(gift, type="mult")
plot(giftComp)
#HoltWinters filtering on births
birthsHW <- HoltWinters(births)
birthsHW
plot(birthsHW)
#forecast for next 48 months
#start from 1952
#blue line: actual prediction, dark gray: 80% confidence interval, light gray: 95% confidence interval
birthsSubset<-window(births, start=1952)
birthsF5 <- hw(birthsSubset, initial="optimal", h=48)
plot(birthsF5)
lines(fitted(birthsF5), col="red")
#dygraphs
dygraph(birthsSubset, main="Birth rates", ylab="Births", xlab="Year") %>%
dyRangeSelector(height=100) %>%
dyShading(from = "1955-1-1", to = "1956-1-1", color = "#FFE6E6") %>%
dyShading(from = "1959-1-1", to = "1960-1-1", color = "#CCEBD6")
